Student Name: Gentzane Pastor Oleagoitia // gentzane.pastor // 540000217
	      Gaizka   Calvo  Orbe       // gaizka.c        // 540001517  
 
Special Directions: 

-Run the demo in release as in debug will take time to run everything it needs.

-You can find the code of Neural Network, Deep Q learning implementation 
and the snake game in the file: 
Source/NeuralNetwork/NeuralNetwork.h
Source/NeuralNetwork/NeuralNetwork.cpp

-At the top left of the window, you can see some data of the current game along
with a slider to change the speed of the snake movement.

-The snake will start learning as soon as you execute the game and the speed will be
the highest in order for the AI to learn as fast as posible, it will automatically 
fall down the speed because of the experience buffer increasing the memory and iterating
in it.

-The parameters that are currently set on the Deep Q learning algorithm, are the ones that gave us the best 
results in term of learning and consistency. It may happen that in the learning process, because it is a 
random process at the beginning, the AI may not learn as well as in other cases, and we recomment multiple
runs for you to see different ways it learns.

-If you would like to change the parameters and see how the AI changes the learning process, you could change 
those in the function Q_Learning::Initialize() located at NeuralNetwork.cpp lines 543-601.

-We also included two videos in this folder to show which is the final state of the project. The first video is 
the start of the game and the second one is a bit later.

My experience working on this project:

The overall experience has been really good. We both liked the topics that we researched as we were really
interested since the beginning. Despite our high interest in this materia, it was a really difficult topic
as these were new things we had to research in depth from the beginning.
